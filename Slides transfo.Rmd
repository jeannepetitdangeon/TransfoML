---
title: "Tweet analysis"
author: "Marion et Jeanne"
date: "2023-10-20"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## DATASET DESCRIPTION

The dataset consists of tweets published by various newspapers that focus on the subject of 4th industrial revolution technologies (AI, Robot, VR, 5g, IoT). The dataset covers the period from 2007 to 2019.

-   id: Unique identifier for each tweet
-   created at: Time at which the tweet was posted
-   text: The actual content of the tweet
-   author.id: Unique identifier for each user
-   public metrics.like count: Number of likes
-   public metrics.retweet count: Number of retweets
-   label: Country code ISO-2

## CLEANING

```{python}
def clean_text(text):
    text = unidecode(text)
    text = text.lower()
    stop_words = set(stopwords.words('english'))
    allowed_special_chars = ['@', '#']
    words = text.split()
    words = [word for word in words if word not in stop_words and not all(char in allowed_special_chars for char in word)]
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word in words]
    cleaned_text = ' '.join(words)

    return cleaned_text

var['text'] = var['text'].apply(clean_text)
print(var.text)
```

## DATA EXPLORATION

![](Plots/Figure%20nbr%20of%20tweets%20by%20year.png){width="396"}

![](Plots/Figure%20like.png){width="258"}

![](Plots/Figure%20like.png){width="264"}

## DATA ANALISIS

```{python}
nlp = spacy.load("en_core_web_sm")
tweets = var['text']
tweet_entities = []
for tweet in tweets:
    doc = nlp(tweet)
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    tweet_entities.append(entities)

var['tweet_entities'] = tweet_entities
print(var.head())
```

```{python}
def analyze_sentiment(text):
    analysis = TextBlob(text)
    if analysis.sentiment.polarity > 0:
        return "Positive"
    elif analysis.sentiment.polarity < 0:
        return "Negative"
    else:
        return "Neutral"
var['sentiment'] = var['text'].apply(analyze_sentiment)
```

## TRANSLATION
```{python}
tr = Translator()

progress_bar = tqdm(total=len(var), desc="Translation Progress")

for i, row in var.iterrows():
    if row["label"] != "en":
        translated_text = None
        retries = 3  # Number of times to retry the translation
        while retries > 0:
            try:
                translation = tr.translate(row["text"], dest='en')
                if translation.text is not None:
                    translated_text = translation.text
                    break  # Translation successful, exit the loop
            except Exception as e:
                print(f"Error translating row {i}: {e}")
                retries -= 1
                time.sleep(2)  # Wait for a moment before retrying

        if translated_text is not None:
            var.at[i, "text"] = translated_text

    progress_bar.update(1)

progress_bar.close()
```

##Zero-Shot Classification
```{python}
import pandas as pd
from transformers import pipeline
tqdm.pandas()

progress_bar = tqdm(total=len(var), desc="Classification Progress")

tweet_topics = ["AI", "Robot", "VR", "5g", "IoT"]
classifier = pipeline("zero-shot-classification")
var['classification_results'] = var['text'][:100].progress_apply(lambda text: classifier(text, tweet_topics)["labels"][0])

progress_bar.update(1)

progress_bar.close()
```