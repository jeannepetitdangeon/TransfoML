{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b46919",
   "metadata": {},
   "source": [
    "# Assignment : Analyzing Twitter Data on 4th Industrial Revolution Technologies\n",
    "\n",
    "We have a sample of 3000 tweets published by the newpapers or their authors over times. The data covers the period from 2007 to 2019.\n",
    "\n",
    "### Variables in the code\n",
    "\n",
    "• id: Unique identifier for each tweet\n",
    "• created at: Time at which the tweet was posted\n",
    "• text: The actual content of the tweet\n",
    "• author.id: Unique identifier for each user\n",
    "• author.name : The name of each Newspaper\n",
    "• public metrics.like count: Number of likes\n",
    "• public metrics.retweet count: Number of retweets\n",
    "• label: Country code ISO-2\n",
    "\n",
    "### Library use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from googletrans import Translator\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03df549",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the file\n",
    "#dat = pd.read_csv('C:/Users/Marion/OneDrive/Documents/cours/strasbourg/M2/Machine learning/transform\\Assignment\\data_tweet_sample_challenge.csv')    \n",
    "dat = pd.read_csv('C:/Users/epcmic/OneDrive/Documents/GitHub/Transformer/Challenge/data_tweet_sample_challenge.csv')\n",
    "\n",
    "var = dat.loc[:,[\"id\",\"created_at\", \"text\", \"author.id\", \"author.name\", \"author.public_metrics.followers_count\",\"public_metrics.like_count\",\"public_metrics.retweet_count\",\"lang\", \"label\"]]\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Data Pre-processing\n",
    "# Text cleaning on the tweet content.\n",
    "\n",
    "def clean_text(text):\n",
    "    text = unidecode(text)\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    allowed_special_chars = ['@', '#']\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words and not all(char in allowed_special_chars for char in word)]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "var['text'] = var['text'].apply(clean_text)\n",
    "print(var.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef7452",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Visualize data in graph\n",
    "\n",
    "#### By Newspapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4386e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# tweets Newspapers by year\n",
    "# =============================================================================\n",
    "#### group data by author.name and compute the number of id for every author\n",
    "count_by_author = dat.groupby(\"author.name\")[\"id\"].count().reset_index()\n",
    "\n",
    "# sort result by label and ascending\n",
    "count_by_author_and_label = dat.groupby([\"label\", \"author.name\"])[\"id\"].count().reset_index().sort_values([\"label\", \"id\"], ascending=[True, False])\n",
    "top_5_by_label = count_by_author_and_label.groupby(\"label\").head(5)\n",
    "print(top_5_by_label)\n",
    "\n",
    "#modelize with a plot\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for i, (label, grp) in enumerate(top_5_by_label.groupby('label')):\n",
    "    ax.barh(y=grp['author.name'], width=grp['id'], color=plt.cm.tab10(i / len(top_5_by_label['label'].unique())), label=label)\n",
    "\n",
    "plt.xlabel(\"Author\")\n",
    "plt.ylabel(\"Number of articles\")\n",
    "plt.title(\"Top 5 of author who tweet the most by country \")\n",
    "plt.show()\n",
    "\n",
    "#### The the distribution of tweets over time, by newspapers\n",
    "data = dat[['author.name', 'created_at', 'public_metrics.retweet_count']]\n",
    "\n",
    "# Count the number of tweets by newspaper\n",
    "tweet_counts = data.groupby(['author.name']).agg({'public_metrics.retweet_count': 'sum'}).reset_index()\n",
    "\n",
    "# Select the top 10 newspapers with the most tweets\n",
    "top_newspapers = tweet_counts.nlargest(10, 'public_metrics.retweet_count')['author.name'].tolist()\n",
    "\n",
    "# Filter the data to keep only the top 10 newspapers\n",
    "data = data[data['author.name'].isin(top_newspapers)]\n",
    "\n",
    "# Group the data by newspaper and tweet year, and aggregate the number of tweets\n",
    "data_by_newspaper = data.groupby(['author.name', dat['created_at'].dt.year]).agg({'public_metrics.retweet_count': 'sum'}).reset_index()\n",
    "\n",
    "# Pivot the data to have one column for each newspaper, and one row for each year\n",
    "pivoted_data = data_by_newspaper.pivot(index='created_at', columns='author.name', values='public_metrics.retweet_count').fillna(0)\n",
    "\n",
    "# Create a bar chart for each year\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.color_palette(\"husl\", len(top_newspapers)))\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "pivoted_data.plot(kind='bar')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of tweets')\n",
    "plt.title('Number of tweets per year for the top 10 newspapers')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# distribution of the 5 newspapers for each country by year\n",
    "# =============================================================================\n",
    "dat['created_at'] = pd.to_datetime(dat['created_at'])\n",
    "dat['year'] = dat['created_at'].dt.year\n",
    "\n",
    "count_by_author_and_label_and_year = dat.groupby(['year', 'author.name', 'label'])['id'].count().reset_index().sort_values(['label', 'year', 'id'], ascending=[True, True, False])\n",
    "\n",
    "# Top 5 of authors by country over time\n",
    "top_5_by_label_and_year = count_by_author_and_label_and_year.groupby(['label', 'year']).head(5)\n",
    "\n",
    "# Graph specifications\n",
    "for label, grp in top_5_by_label_and_year.groupby('label'):\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    for i, (year, year_grp) in enumerate(grp.groupby('year')):\n",
    "        ax.bar(year_grp['author.name'], year_grp['id'], color=plt.cm.tab10(i / len(grp['year'].unique())), label=year)\n",
    "    plt.xlabel('Auteur')\n",
    "    plt.ylabel(\"Nombre d'articles\")\n",
    "    plt.title(f\"Top 5 of authors who tweets the most by country\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "  \n",
    "##### Graph with the number of tweets by country by year \n",
    "\n",
    "var['year'] = pd.DatetimeIndex(var['created_at']).year\n",
    "\n",
    "# Sort of tweets by country over time\n",
    "tweets_by_country_year = var.groupby(['year', 'label']).size().reset_index(name='count')\n",
    "\n",
    "# Graph specifications\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.color_palette(\"pastel\"))\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.barplot(x=\"year\", y=\"count\", hue=\"label\", data=tweets_by_country_year,\n",
    "            palette=sns.color_palette(\"husl\", len(tweets_by_country_year['label'].unique())))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel(\"Number of tweets\")\n",
    "plt.title(\"Number of tweets by country by year\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43326c37",
   "metadata": {},
   "source": [
    "#### Like by followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a240ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# like by followers\n",
    "# =============================================================================\n",
    "# Compute the number of followers\n",
    "var['likes_per_follower'] = var['public_metrics.like_count'] / var['author.public_metrics.followers_count']\n",
    "top_journals_by_country = var.groupby(['label', 'author.name'])['likes_per_follower'].mean().groupby('label', group_keys=False).nlargest(5)\n",
    "print(top_journals_by_country)\n",
    "\n",
    "dat['author.name'].unique()\n",
    "var['created_at'] = pd.to_datetime(var['created_at'])\n",
    "\n",
    "# New colomn for the year and the month\n",
    "var['year'] = var['created_at'].dt.year\n",
    "var['month'] = var['created_at'].dt.month\n",
    "\n",
    "# Merge DataFrames var et top_journals_by_country\n",
    "merged_data = var.merge(top_journals_by_country, on=['author.name', 'label'])\n",
    "\n",
    "# Graph specifications\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='year', y='public_metrics.like_count', hue='month', data=merged_data, ci=None, palette='Set3')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('Number of Like')\n",
    "plt.title('Distribution of Likes byyear and month for the most important newspapers')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "####like by newspapers by country by newspaper\n",
    "data = dat[['public_metrics.like_count', 'author.name', 'label', 'created_at']]\n",
    "\n",
    "# Compute the number of retweets by year, newpapers and countries\n",
    "count_by_year_author_label = data.groupby(['label', 'author.name', dat['created_at'].dt.year])['public_metrics.like_count'].sum().reset_index()\n",
    "\n",
    "# Select newspapers which tweet the most\n",
    "top_author_per_label = count_by_year_author_label.loc[count_by_year_author_label.groupby('label')['public_metrics.retweet_count'].idxmax()]\n",
    "\n",
    "#Merge data to select only the top newspapers\n",
    "merged_data = pd.merge(data, top_author_per_label[['author.name', 'label']], on=['author.name', 'label'], how='inner')\n",
    "\n",
    "# Graph specifications\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.color_palette(\"husl\", len(top_author_per_label['label'].unique())))\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.barplot(x=merged_data['created_at'].dt.year, y=merged_data['public_metrics.like_count'], hue=merged_data['author.name'], palette='husl', ci=None)\n",
    "plt.xlabel('Année')\n",
    "plt.ylabel('Nombre de retweets')\n",
    "plt.title('Distribution des like par année pour chaque journal qui tweet le plus par pays')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "####Number of like by year and country\n",
    "data = dat[['public_metrics.like_count', 'author.name', 'label', 'created_at']]\n",
    "\n",
    "# Compute number of retweets by year, newspapers and country\n",
    "count_by_year_author_label = data.groupby(['label', 'author.name', dat['created_at'].dt.year])['public_metrics.like_count'].sum().reset_index()\n",
    "\n",
    "# Select the newspapers which post the most by country\n",
    "top_author_per_label = count_by_year_author_label.loc[count_by_year_author_label.groupby('label')['public_metrics.like_count'].idxmax()]\n",
    "\n",
    "# Merge to keep only newspapers select\n",
    "merged_data = pd.merge(data, top_author_per_label[['author.name', 'label']], on=['author.name', 'label'], how='inner')\n",
    "\n",
    "# Graph specifications\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.color_palette(\"husl\", len(top_author_per_label['label'].unique())))\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.barplot(x=merged_data['created_at'].dt.year, y=merged_data['public_metrics.like_count'], hue=merged_data['author.name'], palette='husl', ci=None)\n",
    "plt.xlabel('Année')\n",
    "plt.ylabel('Nombre de retweets')\n",
    "plt.title('Distribution des like par année pour chaque journal qui tweet le plus par pays')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd92590",
   "metadata": {},
   "source": [
    "#### Retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of retweets by year and country\n",
    "data = dat[['created_at', 'public_metrics.retweet_count', 'label']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data['year'] = data['created_at'].dt.year\n",
    "\n",
    "# Compute the number of retweets by year and by country\n",
    "count_by_year_label = data.groupby(['label', 'year'])['public_metrics.retweet_count'].sum().reset_index()\n",
    "\n",
    "# Graph\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.barplot(x='year', y='public_metrics.retweet_count', hue='label', data=count_by_year_label)\n",
    "plt.xlabel('Année')\n",
    "plt.ylabel('Number of retweets')\n",
    "plt.title('Number of retweets by year and by country')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Number of retweet by year by newspaper in each country \n",
    "data = dat[['public_metrics.retweet_count', 'author.name', 'label', 'created_at']]\n",
    "\n",
    "# Compute the number of retweets by year, newspapers and by country\n",
    "count_by_year_author_label = data.groupby(['label', 'author.name', dat['created_at'].dt.year])['public_metrics.retweet_count'].sum().reset_index()\n",
    "\n",
    "# Select newspapers which tweet the most\n",
    "top_author_per_label = count_by_year_author_label.loc[count_by_year_author_label.groupby('label')['public_metrics.retweet_count'].idxmax()]\n",
    "\n",
    "#Merge for newspapers select\n",
    "merged_data = pd.merge(data, top_author_per_label[['author.name', 'label']], on=['author.name', 'label'], how='inner')\n",
    "\n",
    "# Graph\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.color_palette(\"husl\", len(top_author_per_label['label'].unique())))\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.barplot(x=merged_data['created_at'].dt.year, y=merged_data['public_metrics.retweet_count'], hue=merged_data['author.name'], palette='husl', ci=None)\n",
    "plt.xlabel('Année')\n",
    "plt.ylabel('Nombre de retweets')\n",
    "plt.title('Distribution des retweets par année pour chaque journal qui tweet le plus par pays')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f643744",
   "metadata": {},
   "source": [
    "#### Extract hashtags from the tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = pd.DataFrame(var)\n",
    "\n",
    "# Function which extract the hashtags (form \"#\")\n",
    "def extract_hashtags(text):\n",
    "    hashtags = re.findall(r'#\\w+', text)\n",
    "    return hashtags\n",
    "\n",
    "#Create a new column where we apply the function\n",
    "var['hashtags'] = var['text'].apply(extract_hashtags)\n",
    "\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de330ef0",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
